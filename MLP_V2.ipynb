{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BooEiEi/project/blob/main/MLP_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbPZs_T9J5BF",
        "outputId": "a770fcec-9aa1-4b31-fe35-46600a737d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive #เชื่อม Google drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/My Drive/project' #เข้า drive\n",
        "data1 = pd.read_csv(os.path.join(path,'df_1.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_absolute_percentage_error"
      ],
      "metadata": {
        "id": "ml8mCLDh2KSY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyperparameter"
      ],
      "metadata": {
        "id": "5bA8pX2Ury9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperParameter(data):\n",
        "  y = data['telomere length (kb)']\n",
        "  X = data.drop('telomere length (kb)',1)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=216)\n",
        "  param_grid = {\n",
        "    'hidden_layer_sizes': [(150,100,50), (120,80,40), (100,50,30), (80,60,40), (60,40,20), (50,30,10)],\n",
        "    'max_iter': [200, 400, 600, 800, 1000],\n",
        "    'activation': ['relu','LeakyReLU','identify'],\n",
        "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
        "    'batch_size':[4, 8, 16, 32, 64],\n",
        "    'random_state':[216]\n",
        "  }\n",
        "  model = MLPRegressor()\n",
        "\n",
        "  gsearch = GridSearchCV(estimator = model,\n",
        "                           param_grid = param_grid                    \n",
        "                          )\n",
        "\n",
        "  gsearch.fit(X_train,y_train)\n",
        "\n",
        "  return gsearch.best_params_"
      ],
      "metadata": {
        "id": "X_4k2jTG3Spd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data1"
      ],
      "metadata": {
        "id": "Y2eR5q5B2HOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1.drop('Unnamed: 0',1,inplace = True)\n",
        "data1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "unjB3wj72It_",
        "outputId": "f7f9cd63-d393-40bb-8e71-6d200b92ff56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-f170cadba2e7>:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data1.drop('Unnamed: 0',1,inplace = True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Sex  AgeSYear     Weight      Height    BMI  Systolic  Diastolic  \\\n",
              "0    2.0      58.0  47.200000  156.000000  19.40   112.000      64.00   \n",
              "1    2.0      57.0  47.400000  153.000000  20.20   114.000      75.00   \n",
              "2    2.0      24.0  53.200000  157.000000  21.60   103.000      69.00   \n",
              "3    2.0      62.0  54.400000  165.000000  20.00    95.000      75.00   \n",
              "4    2.0      86.0  49.000000  154.000000  20.70   129.000      79.00   \n",
              "..   ...       ...        ...         ...    ...       ...        ...   \n",
              "417  2.0      25.0  47.000000  165.000000  17.30   104.000      63.00   \n",
              "418  2.0      31.0  72.200000  168.000000  25.60   123.000      89.00   \n",
              "419  2.0      32.0  54.500000  158.466667  21.68   113.160      71.83   \n",
              "420  1.0      29.0  63.073333  168.866667  22.04   108.465      71.96   \n",
              "421  2.0      31.0  58.066667  160.200000  22.60   112.810      72.72   \n",
              "\n",
              "     HeartRate     SMM  Fat Mass  ...  Uric Acid  Cholesterol  Triglyceride  \\\n",
              "0        70.00  19.741    13.631  ...        4.8        180.0          97.0   \n",
              "1        69.00  19.300    12.500  ...        5.0        176.0          51.0   \n",
              "2        78.00  21.300    14.600  ...        5.2        159.0          45.0   \n",
              "3        83.00  21.600    15.200  ...        4.1        230.0          94.0   \n",
              "4        83.00  19.907    15.369  ...        5.4        183.0          86.0   \n",
              "..         ...     ...       ...  ...        ...          ...           ...   \n",
              "417      89.00  20.387    12.852  ...        4.8        232.0          36.0   \n",
              "418      69.00  25.451    18.258  ...        6.1        187.0          49.0   \n",
              "419      72.30  22.707    21.599  ...        5.1        222.0          58.0   \n",
              "420      83.95  27.607    20.258  ...        6.8        140.0          92.0   \n",
              "421      74.41  23.020    22.436  ...        4.0        243.0         161.0   \n",
              "\n",
              "     HDL-C    LDL   AST   ALT  Alkaline Phos     HbA1c  telomere length (kb)   \n",
              "0     62.0   98.0  25.0  32.0           40.0  5.800000                   7.30  \n",
              "1     72.0   94.0  16.0  16.0           62.0  5.100000                   6.36  \n",
              "2     52.0   98.0  13.0  17.0           50.0  5.400000                   9.71  \n",
              "3     61.0  151.0  18.0  31.0           76.0  5.600000                   6.17  \n",
              "4     39.0  127.0  12.0  22.0           82.0  6.200000                   4.55  \n",
              "..     ...    ...   ...   ...            ...       ...                    ...  \n",
              "417   96.0  128.0  18.0  12.0           46.0  5.393333                   8.98  \n",
              "418   51.0  127.0  21.0  24.0           71.0  5.186667                   8.23  \n",
              "419   79.0  132.0  17.0  10.0           34.0  5.486667                   8.79  \n",
              "420   48.0   73.0  31.0  75.0           69.0  4.973333                   8.93  \n",
              "421   87.0  124.0  24.0  11.0           46.0  6.086667                   7.92  \n",
              "\n",
              "[422 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-122829f0-60b8-451a-99b4-c770eaa1fddd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>AgeSYear</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Height</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Systolic</th>\n",
              "      <th>Diastolic</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>SMM</th>\n",
              "      <th>Fat Mass</th>\n",
              "      <th>...</th>\n",
              "      <th>Uric Acid</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>Triglyceride</th>\n",
              "      <th>HDL-C</th>\n",
              "      <th>LDL</th>\n",
              "      <th>AST</th>\n",
              "      <th>ALT</th>\n",
              "      <th>Alkaline Phos</th>\n",
              "      <th>HbA1c</th>\n",
              "      <th>telomere length (kb)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>47.200000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>19.40</td>\n",
              "      <td>112.000</td>\n",
              "      <td>64.00</td>\n",
              "      <td>70.00</td>\n",
              "      <td>19.741</td>\n",
              "      <td>13.631</td>\n",
              "      <td>...</td>\n",
              "      <td>4.8</td>\n",
              "      <td>180.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>7.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>47.400000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>20.20</td>\n",
              "      <td>114.000</td>\n",
              "      <td>75.00</td>\n",
              "      <td>69.00</td>\n",
              "      <td>19.300</td>\n",
              "      <td>12.500</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>6.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>53.200000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>21.60</td>\n",
              "      <td>103.000</td>\n",
              "      <td>69.00</td>\n",
              "      <td>78.00</td>\n",
              "      <td>21.300</td>\n",
              "      <td>14.600</td>\n",
              "      <td>...</td>\n",
              "      <td>5.2</td>\n",
              "      <td>159.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>9.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>54.400000</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>20.00</td>\n",
              "      <td>95.000</td>\n",
              "      <td>75.00</td>\n",
              "      <td>83.00</td>\n",
              "      <td>21.600</td>\n",
              "      <td>15.200</td>\n",
              "      <td>...</td>\n",
              "      <td>4.1</td>\n",
              "      <td>230.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>6.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>154.000000</td>\n",
              "      <td>20.70</td>\n",
              "      <td>129.000</td>\n",
              "      <td>79.00</td>\n",
              "      <td>83.00</td>\n",
              "      <td>19.907</td>\n",
              "      <td>15.369</td>\n",
              "      <td>...</td>\n",
              "      <td>5.4</td>\n",
              "      <td>183.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>4.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>2.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>17.30</td>\n",
              "      <td>104.000</td>\n",
              "      <td>63.00</td>\n",
              "      <td>89.00</td>\n",
              "      <td>20.387</td>\n",
              "      <td>12.852</td>\n",
              "      <td>...</td>\n",
              "      <td>4.8</td>\n",
              "      <td>232.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>5.393333</td>\n",
              "      <td>8.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>2.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>72.200000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>25.60</td>\n",
              "      <td>123.000</td>\n",
              "      <td>89.00</td>\n",
              "      <td>69.00</td>\n",
              "      <td>25.451</td>\n",
              "      <td>18.258</td>\n",
              "      <td>...</td>\n",
              "      <td>6.1</td>\n",
              "      <td>187.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>5.186667</td>\n",
              "      <td>8.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>2.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>54.500000</td>\n",
              "      <td>158.466667</td>\n",
              "      <td>21.68</td>\n",
              "      <td>113.160</td>\n",
              "      <td>71.83</td>\n",
              "      <td>72.30</td>\n",
              "      <td>22.707</td>\n",
              "      <td>21.599</td>\n",
              "      <td>...</td>\n",
              "      <td>5.1</td>\n",
              "      <td>222.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>5.486667</td>\n",
              "      <td>8.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>63.073333</td>\n",
              "      <td>168.866667</td>\n",
              "      <td>22.04</td>\n",
              "      <td>108.465</td>\n",
              "      <td>71.96</td>\n",
              "      <td>83.95</td>\n",
              "      <td>27.607</td>\n",
              "      <td>20.258</td>\n",
              "      <td>...</td>\n",
              "      <td>6.8</td>\n",
              "      <td>140.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>4.973333</td>\n",
              "      <td>8.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>2.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>58.066667</td>\n",
              "      <td>160.200000</td>\n",
              "      <td>22.60</td>\n",
              "      <td>112.810</td>\n",
              "      <td>72.72</td>\n",
              "      <td>74.41</td>\n",
              "      <td>23.020</td>\n",
              "      <td>22.436</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>6.086667</td>\n",
              "      <td>7.92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>422 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-122829f0-60b8-451a-99b4-c770eaa1fddd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-122829f0-60b8-451a-99b4-c770eaa1fddd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-122829f0-60b8-451a-99b4-c770eaa1fddd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "Scaler = scaler.fit_transform(data1)"
      ],
      "metadata": {
        "id": "HVn9X1I026Ej"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(  Scaler, columns = ['Sex' , 'AgeSYear', 'telomere length (kb)','Weight','Height','BMI','Systolic','Diastolic','HeartRate','SMM','Fat Mass',\n",
        "                                       '% Body fat','waist to hip radio','abdominal circumference','visceral fat area','Glucose','BUN','Creatinine','Uric Acid','Cholesterol',\n",
        "                                       'Triglyceride','HDL-C','LDL','AST','ALT','Alkaline Phos','HbA1c'])\n",
        "df"
      ],
      "metadata": {
        "id": "15SO2i3i260t",
        "outputId": "80b6c6b6-040d-4e2c-a361-dd17f222789a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Sex  AgeSYear  telomere length (kb)    Weight    Height       BMI  \\\n",
              "0    1.0  0.582090              0.154562  0.250000  0.198473  0.531707   \n",
              "1    1.0  0.567164              0.158287  0.181818  0.259542  0.551220   \n",
              "2    1.0  0.074627              0.266294  0.272727  0.366412  0.443902   \n",
              "3    1.0  0.641791              0.288641  0.454545  0.244275  0.365854   \n",
              "4    1.0  1.000000              0.188082  0.204545  0.297710  0.697561   \n",
              "..   ...       ...                   ...       ...       ...       ...   \n",
              "417  1.0  0.089552              0.150838  0.454545  0.038168  0.453659   \n",
              "418  1.0  0.179104              0.620112  0.522727  0.671756  0.639024   \n",
              "419  1.0  0.194030              0.290503  0.306061  0.372519  0.543024   \n",
              "420  0.0  0.149254              0.450155  0.542424  0.400000  0.497220   \n",
              "421  1.0  0.179104              0.356921  0.345455  0.442748  0.539610   \n",
              "\n",
              "     Systolic  Diastolic  HeartRate       SMM  ...  Creatinine  Uric Acid  \\\n",
              "0    0.333333   0.306452   0.101103  0.236189  ...    0.424242   0.438849   \n",
              "1    0.537037   0.290323   0.085409  0.208738  ...    0.454545   0.410072   \n",
              "2    0.425926   0.435484   0.156584  0.259709  ...    0.484848   0.287770   \n",
              "3    0.537037   0.516129   0.167260  0.274272  ...    0.318182   0.798561   \n",
              "4    0.611111   0.516129   0.107011  0.278374  ...    0.515152   0.460432   \n",
              "..        ...        ...        ...       ...  ...         ...        ...   \n",
              "417  0.314815   0.612903   0.124093  0.217282  ...    0.424242   0.812950   \n",
              "418  0.796296   0.290323   0.304306  0.348495  ...    0.621212   0.489209   \n",
              "419  0.478333   0.343548   0.206655  0.429587  ...    0.469697   0.741007   \n",
              "420  0.480741   0.531452   0.381032  0.397039  ...    0.727273   0.151079   \n",
              "421  0.494815   0.377581   0.217794  0.449903  ...    0.303030   0.892086   \n",
              "\n",
              "     Cholesterol  Triglyceride     HDL-C       LDL       AST       ALT  \\\n",
              "0       0.211082      0.402299  0.350365  0.271186  0.376812  0.203390   \n",
              "1       0.089710      0.517241  0.321168  0.118644  0.144928  0.389831   \n",
              "2       0.073879      0.287356  0.350365  0.067797  0.159420  0.288136   \n",
              "3       0.203166      0.390805  0.737226  0.152542  0.362319  0.508475   \n",
              "4       0.182058      0.137931  0.562044  0.050847  0.231884  0.559322   \n",
              "..           ...           ...       ...       ...       ...       ...   \n",
              "417     0.050132      0.793103  0.569343  0.152542  0.086957  0.254237   \n",
              "418     0.084433      0.275862  0.562044  0.203390  0.260870  0.466102   \n",
              "419     0.108179      0.597701  0.598540  0.135593  0.057971  0.152542   \n",
              "420     0.197889      0.241379  0.167883  0.372881  1.000000  0.449153   \n",
              "421     0.379947      0.689655  0.540146  0.254237  0.072464  0.254237   \n",
              "\n",
              "     Alkaline Phos     HbA1c  \n",
              "0         0.540984  0.119472  \n",
              "1         0.426230  0.083010  \n",
              "2         0.475410  0.212956  \n",
              "3         0.508197  0.075640  \n",
              "4         0.606557  0.012801  \n",
              "..             ...       ...  \n",
              "417       0.474317  0.184639  \n",
              "418       0.440437  0.155547  \n",
              "419       0.489617  0.177269  \n",
              "420       0.405464  0.182700  \n",
              "421       0.587978  0.143522  \n",
              "\n",
              "[422 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a93de7c-bd4b-4d5c-815c-13e5a1a92212\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>AgeSYear</th>\n",
              "      <th>telomere length (kb)</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Height</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Systolic</th>\n",
              "      <th>Diastolic</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>SMM</th>\n",
              "      <th>...</th>\n",
              "      <th>Creatinine</th>\n",
              "      <th>Uric Acid</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>Triglyceride</th>\n",
              "      <th>HDL-C</th>\n",
              "      <th>LDL</th>\n",
              "      <th>AST</th>\n",
              "      <th>ALT</th>\n",
              "      <th>Alkaline Phos</th>\n",
              "      <th>HbA1c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.582090</td>\n",
              "      <td>0.154562</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.198473</td>\n",
              "      <td>0.531707</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.306452</td>\n",
              "      <td>0.101103</td>\n",
              "      <td>0.236189</td>\n",
              "      <td>...</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.438849</td>\n",
              "      <td>0.211082</td>\n",
              "      <td>0.402299</td>\n",
              "      <td>0.350365</td>\n",
              "      <td>0.271186</td>\n",
              "      <td>0.376812</td>\n",
              "      <td>0.203390</td>\n",
              "      <td>0.540984</td>\n",
              "      <td>0.119472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.567164</td>\n",
              "      <td>0.158287</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.259542</td>\n",
              "      <td>0.551220</td>\n",
              "      <td>0.537037</td>\n",
              "      <td>0.290323</td>\n",
              "      <td>0.085409</td>\n",
              "      <td>0.208738</td>\n",
              "      <td>...</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.410072</td>\n",
              "      <td>0.089710</td>\n",
              "      <td>0.517241</td>\n",
              "      <td>0.321168</td>\n",
              "      <td>0.118644</td>\n",
              "      <td>0.144928</td>\n",
              "      <td>0.389831</td>\n",
              "      <td>0.426230</td>\n",
              "      <td>0.083010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.074627</td>\n",
              "      <td>0.266294</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.366412</td>\n",
              "      <td>0.443902</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.435484</td>\n",
              "      <td>0.156584</td>\n",
              "      <td>0.259709</td>\n",
              "      <td>...</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.287770</td>\n",
              "      <td>0.073879</td>\n",
              "      <td>0.287356</td>\n",
              "      <td>0.350365</td>\n",
              "      <td>0.067797</td>\n",
              "      <td>0.159420</td>\n",
              "      <td>0.288136</td>\n",
              "      <td>0.475410</td>\n",
              "      <td>0.212956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.641791</td>\n",
              "      <td>0.288641</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.244275</td>\n",
              "      <td>0.365854</td>\n",
              "      <td>0.537037</td>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.167260</td>\n",
              "      <td>0.274272</td>\n",
              "      <td>...</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>0.798561</td>\n",
              "      <td>0.203166</td>\n",
              "      <td>0.390805</td>\n",
              "      <td>0.737226</td>\n",
              "      <td>0.152542</td>\n",
              "      <td>0.362319</td>\n",
              "      <td>0.508475</td>\n",
              "      <td>0.508197</td>\n",
              "      <td>0.075640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.188082</td>\n",
              "      <td>0.204545</td>\n",
              "      <td>0.297710</td>\n",
              "      <td>0.697561</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.107011</td>\n",
              "      <td>0.278374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.515152</td>\n",
              "      <td>0.460432</td>\n",
              "      <td>0.182058</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0.562044</td>\n",
              "      <td>0.050847</td>\n",
              "      <td>0.231884</td>\n",
              "      <td>0.559322</td>\n",
              "      <td>0.606557</td>\n",
              "      <td>0.012801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.089552</td>\n",
              "      <td>0.150838</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.038168</td>\n",
              "      <td>0.453659</td>\n",
              "      <td>0.314815</td>\n",
              "      <td>0.612903</td>\n",
              "      <td>0.124093</td>\n",
              "      <td>0.217282</td>\n",
              "      <td>...</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.812950</td>\n",
              "      <td>0.050132</td>\n",
              "      <td>0.793103</td>\n",
              "      <td>0.569343</td>\n",
              "      <td>0.152542</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.254237</td>\n",
              "      <td>0.474317</td>\n",
              "      <td>0.184639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.179104</td>\n",
              "      <td>0.620112</td>\n",
              "      <td>0.522727</td>\n",
              "      <td>0.671756</td>\n",
              "      <td>0.639024</td>\n",
              "      <td>0.796296</td>\n",
              "      <td>0.290323</td>\n",
              "      <td>0.304306</td>\n",
              "      <td>0.348495</td>\n",
              "      <td>...</td>\n",
              "      <td>0.621212</td>\n",
              "      <td>0.489209</td>\n",
              "      <td>0.084433</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.562044</td>\n",
              "      <td>0.203390</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.466102</td>\n",
              "      <td>0.440437</td>\n",
              "      <td>0.155547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.194030</td>\n",
              "      <td>0.290503</td>\n",
              "      <td>0.306061</td>\n",
              "      <td>0.372519</td>\n",
              "      <td>0.543024</td>\n",
              "      <td>0.478333</td>\n",
              "      <td>0.343548</td>\n",
              "      <td>0.206655</td>\n",
              "      <td>0.429587</td>\n",
              "      <td>...</td>\n",
              "      <td>0.469697</td>\n",
              "      <td>0.741007</td>\n",
              "      <td>0.108179</td>\n",
              "      <td>0.597701</td>\n",
              "      <td>0.598540</td>\n",
              "      <td>0.135593</td>\n",
              "      <td>0.057971</td>\n",
              "      <td>0.152542</td>\n",
              "      <td>0.489617</td>\n",
              "      <td>0.177269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.149254</td>\n",
              "      <td>0.450155</td>\n",
              "      <td>0.542424</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.497220</td>\n",
              "      <td>0.480741</td>\n",
              "      <td>0.531452</td>\n",
              "      <td>0.381032</td>\n",
              "      <td>0.397039</td>\n",
              "      <td>...</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.151079</td>\n",
              "      <td>0.197889</td>\n",
              "      <td>0.241379</td>\n",
              "      <td>0.167883</td>\n",
              "      <td>0.372881</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.449153</td>\n",
              "      <td>0.405464</td>\n",
              "      <td>0.182700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.179104</td>\n",
              "      <td>0.356921</td>\n",
              "      <td>0.345455</td>\n",
              "      <td>0.442748</td>\n",
              "      <td>0.539610</td>\n",
              "      <td>0.494815</td>\n",
              "      <td>0.377581</td>\n",
              "      <td>0.217794</td>\n",
              "      <td>0.449903</td>\n",
              "      <td>...</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.892086</td>\n",
              "      <td>0.379947</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.540146</td>\n",
              "      <td>0.254237</td>\n",
              "      <td>0.072464</td>\n",
              "      <td>0.254237</td>\n",
              "      <td>0.587978</td>\n",
              "      <td>0.143522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>422 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a93de7c-bd4b-4d5c-815c-13e5a1a92212')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a93de7c-bd4b-4d5c-815c-13e5a1a92212 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a93de7c-bd4b-4d5c-815c-13e5a1a92212');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperParameter(df)"
      ],
      "metadata": {
        "id": "z1BSyJsfJ9Ta",
        "outputId": "2db2d84a-9019-4664-b801-bfd5a55683e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-1834599e46ea>:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  X = data.drop('telomere length (kb)',1)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "13500 fits failed out of a total of 20250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6750 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 384, in _fit\n",
            "    self._validate_hyperparameters()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 493, in _validate_hyperparameters\n",
            "    raise ValueError(\n",
            "ValueError: The activation 'LeakyReLU' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6750 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 384, in _fit\n",
            "    self._validate_hyperparameters()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 493, in _validate_hyperparameters\n",
            "    raise ValueError(\n",
            "ValueError: The activation 'identify' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.88426553 0.99239361 0.99455293 ...        nan        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:984: RuntimeWarning: invalid value encountered in cast\n",
            "  results[\"rank_%s\" % key_name] = np.asarray(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'batch_size': 4,\n",
              " 'hidden_layer_sizes': (150, 100, 50),\n",
              " 'learning_rate_init': 0.001,\n",
              " 'max_iter': 200,\n",
              " 'random_state': 216,\n",
              " 'solver': 'sgd'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['telomere length (kb)']\n",
        "X = df.drop('telomere length (kb)',1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWhJ_WBD27k5",
        "outputId": "a147617f-4102-43c6-f792-4648c179f666"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-2081a7e829a9>:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  X = df.drop('telomere length (kb)',1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=216)"
      ],
      "metadata": {
        "id": "1jQwk5bU29yc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLPRegressor(hidden_layer_sizes=(150, 100, 50),activation = 'relu',solver = 'sgd',\n",
        "                     learning_rate_init = 0.001, max_iter = 200, batch_size = 4, random_state=216)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFzxXfOH2-aH",
        "outputId": "991e3f09-24b2-468d-ca79-e7bf2f1d63b4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(batch_size=4, hidden_layer_sizes=(150, 100, 50), random_state=216,\n",
              "             solver='sgd')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "a75dFHJs3R06"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "print('R2 Value Train:',metrics.r2_score(y_train, model.predict(X_train)))\n",
        "print('MSE Train:',metrics.mean_squared_error(y_train, model.predict(X_train)))\n",
        "print('MAE Train:',metrics.mean_absolute_error(y_train, model.predict(X_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HmpE6nD3VMO",
        "outputId": "6b3a3e7b-ca9b-43ad-d7c4-64106516f24c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Value Train: 0.9217611233792693\n",
            "MSE Train: 0.0027562583275257627\n",
            "MAE Train: 0.04019131634610395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('MAPE :',mean_absolute_percentage_error(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LFsMi7G3XRy",
        "outputId": "f917a55f-3efc-4354-8191-3b80876c6c67"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAPE : 0.18113070571368786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "print('R2 Value Test:',metrics.r2_score(y_test, y_pred))\n",
        "print('MSE Test:',metrics.mean_squared_error(y_test, y_pred))\n",
        "print('MAE Test:',metrics.mean_absolute_error(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1zYYJAx3YID",
        "outputId": "baad4ff7-c9e7-487a-8d09-125c10e98815"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Value Test: 0.9115572914806856\n",
            "MSE Test: 0.002626478846807712\n",
            "MAE Test: 0.03976309214167844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(y_pred, hist = False, color = 'r', label = 'Predicted Values')\n",
        "sns.distplot(y_test, hist = False, color = 'b', label = 'Actual Values')\n",
        "plt.title('Actual vs Predicted Values', fontsize = 16)\n",
        "plt.xlabel('Values', fontsize = 12)\n",
        "plt.ylabel('Frequency', fontsize = 12)\n",
        "plt.legend(loc = 'upper left', fontsize = 13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "X23AQzWGd0LH",
        "outputId": "496cfdfe-935f-468c-ed54-68c807db31e4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb305edbc10>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data2"
      ],
      "metadata": {
        "id": "5AJz7f3a34d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = pd.read_csv(os.path.join(path,'df_2.csv'))\n",
        "data2.drop('Unnamed: 0',1,inplace = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PsubGiO36Sf",
        "outputId": "45ffa267-81b4-4c11-d903-c79b64fabb8d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-9295e0cecbd9>:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data2.drop('Unnamed: 0',1,inplace = True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "Scaler = scaler.fit_transform(data2)"
      ],
      "metadata": {
        "id": "iXSepfPK37Wt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame(  Scaler, columns = ['Sex' , 'AgeSYear', 'telomere length (kb)','Weight','Height','BMI','Systolic','Diastolic','HeartRate','SMM','Fat Mass',\n",
        "                                       '% Body fat','waist to hip radio','abdominal circumference','visceral fat area','Glucose','BUN','Creatinine','Uric Acid','Cholesterol',\n",
        "                                       'Triglyceride','HDL-C','LDL','AST','ALT','Alkaline Phos','HbA1c'])\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "5Q3gyPfh382r",
        "outputId": "d4508c31-a834-4770-a343-e403a21f4cd3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Sex  AgeSYear  telomere length (kb)    Weight    Height       BMI  \\\n",
              "0    1.0  0.582090              0.154562  0.250000  0.198473  0.531707   \n",
              "1    1.0  0.567164              0.158287  0.181818  0.259542  0.551220   \n",
              "2    1.0  0.074627              0.266294  0.272727  0.366412  0.443902   \n",
              "3    1.0  0.641791              0.288641  0.454545  0.244275  0.365854   \n",
              "4    1.0  1.000000              0.188082  0.204545  0.297710  0.697561   \n",
              "..   ...       ...                   ...       ...       ...       ...   \n",
              "417  1.0  0.089552              0.150838  0.454545  0.038168  0.453659   \n",
              "418  1.0  0.179104              0.620112  0.522727  0.671756  0.639024   \n",
              "419  1.0  0.194030              0.498250  0.271818  0.700763  0.569366   \n",
              "420  0.0  0.149254              0.537579  0.565909  0.539695  0.582488   \n",
              "421  1.0  0.179104              0.428957  0.374091  0.554198  0.544780   \n",
              "\n",
              "     Systolic  Diastolic  HeartRate       SMM  ...  Creatinine  Uric Acid  \\\n",
              "0    0.333333   0.306452   0.099431  0.230680  ...    0.424242   0.438849   \n",
              "1    0.537037   0.290323   0.085409  0.208738  ...    0.454545   0.410072   \n",
              "2    0.425926   0.435484   0.156584  0.259709  ...    0.484848   0.287770   \n",
              "3    0.537037   0.516129   0.167260  0.274272  ...    0.318182   0.798561   \n",
              "4    0.611111   0.516129   0.112349  0.300850  ...    0.515152   0.460432   \n",
              "..        ...        ...        ...       ...  ...         ...        ...   \n",
              "417  0.314815   0.612903   0.120961  0.234903  ...    0.424242   0.812950   \n",
              "418  0.796296   0.290323   0.298434  0.346626  ...    0.621212   0.489209   \n",
              "419  0.503148   0.382581   0.237473  0.506432  ...    0.469697   0.741007   \n",
              "420  0.546296   0.554355   0.457402  0.309175  ...    0.727273   0.151079   \n",
              "421  0.468704   0.367258   0.227580  0.435704  ...    0.303030   0.892086   \n",
              "\n",
              "     Cholesterol  Triglyceride     HDL-C       LDL       AST       ALT  \\\n",
              "0       0.211082      0.402299  0.350365  0.271186  0.376812  0.203390   \n",
              "1       0.089710      0.517241  0.321168  0.118644  0.144928  0.389831   \n",
              "2       0.073879      0.287356  0.350365  0.067797  0.159420  0.288136   \n",
              "3       0.203166      0.390805  0.737226  0.152542  0.362319  0.508475   \n",
              "4       0.182058      0.137931  0.562044  0.050847  0.231884  0.559322   \n",
              "..           ...           ...       ...       ...       ...       ...   \n",
              "417     0.050132      0.793103  0.569343  0.152542  0.086957  0.254237   \n",
              "418     0.084433      0.275862  0.562044  0.203390  0.260870  0.466102   \n",
              "419     0.108179      0.597701  0.598540  0.135593  0.057971  0.152542   \n",
              "420     0.197889      0.241379  0.167883  0.372881  1.000000  0.449153   \n",
              "421     0.379947      0.689655  0.540146  0.254237  0.072464  0.254237   \n",
              "\n",
              "     Alkaline Phos     HbA1c  \n",
              "0         0.540984  0.119472  \n",
              "1         0.426230  0.083010  \n",
              "2         0.475410  0.212956  \n",
              "3         0.508197  0.075640  \n",
              "4         0.606557  0.012801  \n",
              "..             ...       ...  \n",
              "417       0.461639  0.184639  \n",
              "418       0.445082  0.155547  \n",
              "419       0.498689  0.177269  \n",
              "420       0.528689  0.182700  \n",
              "421       0.380000  0.143522  \n",
              "\n",
              "[422 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a605d340-9f05-4cb2-adca-9bae76dd8287\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>AgeSYear</th>\n",
              "      <th>telomere length (kb)</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Height</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Systolic</th>\n",
              "      <th>Diastolic</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>SMM</th>\n",
              "      <th>...</th>\n",
              "      <th>Creatinine</th>\n",
              "      <th>Uric Acid</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>Triglyceride</th>\n",
              "      <th>HDL-C</th>\n",
              "      <th>LDL</th>\n",
              "      <th>AST</th>\n",
              "      <th>ALT</th>\n",
              "      <th>Alkaline Phos</th>\n",
              "      <th>HbA1c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.582090</td>\n",
              "      <td>0.154562</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.198473</td>\n",
              "      <td>0.531707</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.306452</td>\n",
              "      <td>0.099431</td>\n",
              "      <td>0.230680</td>\n",
              "      <td>...</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.438849</td>\n",
              "      <td>0.211082</td>\n",
              "      <td>0.402299</td>\n",
              "      <td>0.350365</td>\n",
              "      <td>0.271186</td>\n",
              "      <td>0.376812</td>\n",
              "      <td>0.203390</td>\n",
              "      <td>0.540984</td>\n",
              "      <td>0.119472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.567164</td>\n",
              "      <td>0.158287</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.259542</td>\n",
              "      <td>0.551220</td>\n",
              "      <td>0.537037</td>\n",
              "      <td>0.290323</td>\n",
              "      <td>0.085409</td>\n",
              "      <td>0.208738</td>\n",
              "      <td>...</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.410072</td>\n",
              "      <td>0.089710</td>\n",
              "      <td>0.517241</td>\n",
              "      <td>0.321168</td>\n",
              "      <td>0.118644</td>\n",
              "      <td>0.144928</td>\n",
              "      <td>0.389831</td>\n",
              "      <td>0.426230</td>\n",
              "      <td>0.083010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.074627</td>\n",
              "      <td>0.266294</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.366412</td>\n",
              "      <td>0.443902</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.435484</td>\n",
              "      <td>0.156584</td>\n",
              "      <td>0.259709</td>\n",
              "      <td>...</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.287770</td>\n",
              "      <td>0.073879</td>\n",
              "      <td>0.287356</td>\n",
              "      <td>0.350365</td>\n",
              "      <td>0.067797</td>\n",
              "      <td>0.159420</td>\n",
              "      <td>0.288136</td>\n",
              "      <td>0.475410</td>\n",
              "      <td>0.212956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.641791</td>\n",
              "      <td>0.288641</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.244275</td>\n",
              "      <td>0.365854</td>\n",
              "      <td>0.537037</td>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.167260</td>\n",
              "      <td>0.274272</td>\n",
              "      <td>...</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>0.798561</td>\n",
              "      <td>0.203166</td>\n",
              "      <td>0.390805</td>\n",
              "      <td>0.737226</td>\n",
              "      <td>0.152542</td>\n",
              "      <td>0.362319</td>\n",
              "      <td>0.508475</td>\n",
              "      <td>0.508197</td>\n",
              "      <td>0.075640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.188082</td>\n",
              "      <td>0.204545</td>\n",
              "      <td>0.297710</td>\n",
              "      <td>0.697561</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.112349</td>\n",
              "      <td>0.300850</td>\n",
              "      <td>...</td>\n",
              "      <td>0.515152</td>\n",
              "      <td>0.460432</td>\n",
              "      <td>0.182058</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0.562044</td>\n",
              "      <td>0.050847</td>\n",
              "      <td>0.231884</td>\n",
              "      <td>0.559322</td>\n",
              "      <td>0.606557</td>\n",
              "      <td>0.012801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.089552</td>\n",
              "      <td>0.150838</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.038168</td>\n",
              "      <td>0.453659</td>\n",
              "      <td>0.314815</td>\n",
              "      <td>0.612903</td>\n",
              "      <td>0.120961</td>\n",
              "      <td>0.234903</td>\n",
              "      <td>...</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.812950</td>\n",
              "      <td>0.050132</td>\n",
              "      <td>0.793103</td>\n",
              "      <td>0.569343</td>\n",
              "      <td>0.152542</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.254237</td>\n",
              "      <td>0.461639</td>\n",
              "      <td>0.184639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.179104</td>\n",
              "      <td>0.620112</td>\n",
              "      <td>0.522727</td>\n",
              "      <td>0.671756</td>\n",
              "      <td>0.639024</td>\n",
              "      <td>0.796296</td>\n",
              "      <td>0.290323</td>\n",
              "      <td>0.298434</td>\n",
              "      <td>0.346626</td>\n",
              "      <td>...</td>\n",
              "      <td>0.621212</td>\n",
              "      <td>0.489209</td>\n",
              "      <td>0.084433</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.562044</td>\n",
              "      <td>0.203390</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.466102</td>\n",
              "      <td>0.445082</td>\n",
              "      <td>0.155547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.194030</td>\n",
              "      <td>0.498250</td>\n",
              "      <td>0.271818</td>\n",
              "      <td>0.700763</td>\n",
              "      <td>0.569366</td>\n",
              "      <td>0.503148</td>\n",
              "      <td>0.382581</td>\n",
              "      <td>0.237473</td>\n",
              "      <td>0.506432</td>\n",
              "      <td>...</td>\n",
              "      <td>0.469697</td>\n",
              "      <td>0.741007</td>\n",
              "      <td>0.108179</td>\n",
              "      <td>0.597701</td>\n",
              "      <td>0.598540</td>\n",
              "      <td>0.135593</td>\n",
              "      <td>0.057971</td>\n",
              "      <td>0.152542</td>\n",
              "      <td>0.498689</td>\n",
              "      <td>0.177269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.149254</td>\n",
              "      <td>0.537579</td>\n",
              "      <td>0.565909</td>\n",
              "      <td>0.539695</td>\n",
              "      <td>0.582488</td>\n",
              "      <td>0.546296</td>\n",
              "      <td>0.554355</td>\n",
              "      <td>0.457402</td>\n",
              "      <td>0.309175</td>\n",
              "      <td>...</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.151079</td>\n",
              "      <td>0.197889</td>\n",
              "      <td>0.241379</td>\n",
              "      <td>0.167883</td>\n",
              "      <td>0.372881</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.449153</td>\n",
              "      <td>0.528689</td>\n",
              "      <td>0.182700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.179104</td>\n",
              "      <td>0.428957</td>\n",
              "      <td>0.374091</td>\n",
              "      <td>0.554198</td>\n",
              "      <td>0.544780</td>\n",
              "      <td>0.468704</td>\n",
              "      <td>0.367258</td>\n",
              "      <td>0.227580</td>\n",
              "      <td>0.435704</td>\n",
              "      <td>...</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.892086</td>\n",
              "      <td>0.379947</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.540146</td>\n",
              "      <td>0.254237</td>\n",
              "      <td>0.072464</td>\n",
              "      <td>0.254237</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>0.143522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>422 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a605d340-9f05-4cb2-adca-9bae76dd8287')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a605d340-9f05-4cb2-adca-9bae76dd8287 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a605d340-9f05-4cb2-adca-9bae76dd8287');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperParameter(df2)"
      ],
      "metadata": {
        "id": "rTWwPoXQlJHc",
        "outputId": "2e6d163a-ccd6-4b13-e9e1-4abd4e173de8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-1834599e46ea>:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  X = data.drop('telomere length (kb)',1)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "13500 fits failed out of a total of 20250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6750 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 384, in _fit\n",
            "    self._validate_hyperparameters()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 493, in _validate_hyperparameters\n",
            "    raise ValueError(\n",
            "ValueError: The activation 'LeakyReLU' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6750 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 384, in _fit\n",
            "    self._validate_hyperparameters()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 493, in _validate_hyperparameters\n",
            "    raise ValueError(\n",
            "ValueError: The activation 'identify' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.88358938 0.99023312 0.99274041 ...        nan        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:984: RuntimeWarning: invalid value encountered in cast\n",
            "  results[\"rank_%s\" % key_name] = np.asarray(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'batch_size': 4,\n",
              " 'hidden_layer_sizes': (150, 100, 50),\n",
              " 'learning_rate_init': 0.001,\n",
              " 'max_iter': 200,\n",
              " 'random_state': 216,\n",
              " 'solver': 'sgd'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df2['telomere length (kb)'].values\n",
        "X = df2.drop('telomere length (kb)',1).values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hds5eRdG39LS",
        "outputId": "09a60556-03dd-4421-ea90-9f49c194e3f8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-8bd2b2c93927>:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  X = df2.drop('telomere length (kb)',1).values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=216)"
      ],
      "metadata": {
        "id": "r-zUbarZ3_ca"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLPRegressor(hidden_layer_sizes=(150, 100, 50),activation = 'relu',solver = 'sgd',\n",
        "                     learning_rate_init = 0.001, max_iter = 200, batch_size = 4, random_state=216)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrTLGA-C4Axm",
        "outputId": "b609048f-05a2-4251-e922-1ceaa27d9eb0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(batch_size=4, hidden_layer_sizes=(150, 100, 50), random_state=216,\n",
              "             solver='sgd')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "khaX96uCcmJk"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "print('R2 Value Train:',metrics.r2_score(y_train, model.predict(X_train)))\n",
        "print('MSE Train:',metrics.mean_squared_error(y_train, model.predict(X_train)))\n",
        "print('MAE Train:',metrics.mean_absolute_error(y_train, model.predict(X_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1CzPHnY4C16",
        "outputId": "221e5fdc-7334-413f-cfd0-61477f956ac4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Value Train: 0.9239385077883571\n",
            "MSE Train: 0.00268994744868291\n",
            "MAE Train: 0.039937556248450676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('MAPE :',mean_absolute_percentage_error(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhdkUkJr4FLo",
        "outputId": "e9b5fd02-81cb-4434-ad9c-f969691f7dfa"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAPE : 0.17839002045062957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "print('R2 Value Test:',metrics.r2_score(y_test, y_pred))\n",
        "print('MSE Test:',metrics.mean_squared_error(y_test, y_pred))\n",
        "print('MAE Test:',metrics.mean_absolute_error(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G34aW2N44FaS",
        "outputId": "37cf55a7-949b-40ae-adef-3adc57d6785c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Value Test: 0.9062723051156134\n",
            "MSE Test: 0.0027923009352130985\n",
            "MAE Test: 0.040111887486189275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(y_pred, hist = False, color = 'r', label = 'Predicted Values')\n",
        "sns.distplot(y_test, hist = False, color = 'b', label = 'Actual Values')\n",
        "plt.title('Actual vs Predicted Values', fontsize = 16)\n",
        "plt.xlabel('Values', fontsize = 12)\n",
        "plt.ylabel('Frequency', fontsize = 12)\n",
        "plt.legend(loc = 'upper left', fontsize = 13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "BVM7shiEdyVS",
        "outputId": "cdba1027-d953-436a-cc42-c8bbe5f89de7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb30373b850>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data control"
      ],
      "metadata": {
        "id": "z2zOcj2Z4SEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_file_path = os.path.join(path,'df_control.csv') #ไปที่ไฟล์ confirmed-cases-since-280265.csv\n",
        "data3 = pd.read_csv(data_file_path)\n",
        "data3.drop({'Unnamed: 0'},1,inplace = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQJlM6ps4Two",
        "outputId": "e5f828d9-4899-48bf-b285-21733f89dbf1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-bf1a70202b09>:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data3.drop({'Unnamed: 0'},1,inplace = True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "Scaler = scaler.fit_transform(data3)"
      ],
      "metadata": {
        "id": "QcRTWRtS4Tjn"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.DataFrame(Scaler, columns = ['Sex' , 'AgeSYear', 'telomere length (kb)','Weight','Height','BMI','Systolic','Diastolic','HeartRate','SMM','Fat Mass',\n",
        "                                       '% Body fat','waist to hip radio','abdominal circumference','visceral fat area','Glucose','BUN','Creatinine','Uric Acid','Cholesterol',\n",
        "                                       'Triglyceride','HDL-C','LDL','AST','ALT','Alkaline Phos','HbA1c'])"
      ],
      "metadata": {
        "id": "ApBojhBk4WA6"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "HIvxsWPc4q3p",
        "outputId": "2de64b5d-b9d6-46e9-d5eb-7847460fd2a6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Sex  AgeSYear  telomere length (kb)  Weight  Height     BMI  Systolic  \\\n",
              "0    1.0    0.6607                0.2759  0.1274  0.1818  0.2845    0.4444   \n",
              "1    1.0    0.0714                0.7202  0.2394  0.2727  0.4052    0.2698   \n",
              "2    1.0    0.7500                0.2507  0.2625  0.4545  0.2672    0.1429   \n",
              "3    1.0    0.2679                0.3912  0.2992  0.3636  0.4138    0.1429   \n",
              "4    0.0    0.4643                0.2971  0.6081  0.5682  0.6983    0.7460   \n",
              "..   ...       ...                   ...     ...     ...     ...       ...   \n",
              "148  0.0    0.7143                0.2029  0.6023  0.5682  0.6897    0.7143   \n",
              "149  0.0    0.6786                0.1021  0.4093  0.5227  0.4397    0.2698   \n",
              "150  1.0    0.3929                0.6897  0.2838  0.4545  0.3017    0.2540   \n",
              "151  1.0    0.7321                0.2361  0.4054  0.3182  0.6466    0.4921   \n",
              "152  1.0    0.1964                0.6844  0.3359  0.5455  0.3017    0.3492   \n",
              "\n",
              "     Diastolic  HeartRate     SMM  ...  Creatinine  Uric Acid  Cholesterol  \\\n",
              "0       0.6216     0.3103  0.0854  ...         0.6     0.5172       0.4091   \n",
              "1       0.4595     0.4655  0.1566  ...         0.4     0.5517       0.2803   \n",
              "2       0.6216     0.5517  0.1673  ...         0.3     0.3621       0.8182   \n",
              "3       0.1351     0.3621  0.1993  ...         0.2     0.5172       0.5758   \n",
              "4       0.6757     0.9655  0.4377  ...         0.5     0.8448       0.5455   \n",
              "..         ...        ...     ...  ...         ...        ...          ...   \n",
              "148     0.5946     0.3103  0.4840  ...         0.5     0.8448       0.4545   \n",
              "149     0.6486     0.3621  0.3879  ...         0.6     0.8276       0.5227   \n",
              "150     0.0000     0.4483  0.2135  ...         0.4     0.4655       0.6818   \n",
              "151     0.2162     0.3621  0.2313  ...         0.4     0.5345       0.8561   \n",
              "152     0.4595     0.3793  0.2883  ...         0.3     0.3966       0.5909   \n",
              "\n",
              "     Triglyceride   HDL-C     LDL     AST     ALT  Alkaline Phos   HbA1c  \n",
              "0          0.1323  0.7407  0.2909  0.1186  0.0000         0.5823  0.4262  \n",
              "1          0.1089  0.3704  0.3273  0.0678  0.0323         0.4304  0.4754  \n",
              "2          0.2996  0.5370  0.8091  0.1525  0.4839         0.7595  0.5082  \n",
              "3          0.1167  0.6667  0.5273  0.1186  0.1290         0.2405  0.4262  \n",
              "4          0.1790  0.5185  0.5455  0.1017  0.0968         0.6709  0.4426  \n",
              "..            ...     ...     ...     ...     ...            ...     ...  \n",
              "148        0.6304  0.1296  0.4091  0.4576  0.4839         0.7975  0.6557  \n",
              "149        0.1751  0.2778  0.6364  0.1186  0.5484         0.3291  0.7049  \n",
              "150        0.1984  0.5741  0.6636  0.0339  0.0000         0.2152  0.3770  \n",
              "151        0.1907  0.4444  0.9455  0.1017  0.2258         0.3544  0.4754  \n",
              "152        0.1051  0.4444  0.6636  0.0847  0.1613         0.1899  0.3607  \n",
              "\n",
              "[153 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57bce0a5-9848-44ed-b2e5-3500c2dae5d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>AgeSYear</th>\n",
              "      <th>telomere length (kb)</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Height</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Systolic</th>\n",
              "      <th>Diastolic</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>SMM</th>\n",
              "      <th>...</th>\n",
              "      <th>Creatinine</th>\n",
              "      <th>Uric Acid</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>Triglyceride</th>\n",
              "      <th>HDL-C</th>\n",
              "      <th>LDL</th>\n",
              "      <th>AST</th>\n",
              "      <th>ALT</th>\n",
              "      <th>Alkaline Phos</th>\n",
              "      <th>HbA1c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6607</td>\n",
              "      <td>0.2759</td>\n",
              "      <td>0.1274</td>\n",
              "      <td>0.1818</td>\n",
              "      <td>0.2845</td>\n",
              "      <td>0.4444</td>\n",
              "      <td>0.6216</td>\n",
              "      <td>0.3103</td>\n",
              "      <td>0.0854</td>\n",
              "      <td>...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.5172</td>\n",
              "      <td>0.4091</td>\n",
              "      <td>0.1323</td>\n",
              "      <td>0.7407</td>\n",
              "      <td>0.2909</td>\n",
              "      <td>0.1186</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5823</td>\n",
              "      <td>0.4262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0714</td>\n",
              "      <td>0.7202</td>\n",
              "      <td>0.2394</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.2698</td>\n",
              "      <td>0.4595</td>\n",
              "      <td>0.4655</td>\n",
              "      <td>0.1566</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.5517</td>\n",
              "      <td>0.2803</td>\n",
              "      <td>0.1089</td>\n",
              "      <td>0.3704</td>\n",
              "      <td>0.3273</td>\n",
              "      <td>0.0678</td>\n",
              "      <td>0.0323</td>\n",
              "      <td>0.4304</td>\n",
              "      <td>0.4754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.2507</td>\n",
              "      <td>0.2625</td>\n",
              "      <td>0.4545</td>\n",
              "      <td>0.2672</td>\n",
              "      <td>0.1429</td>\n",
              "      <td>0.6216</td>\n",
              "      <td>0.5517</td>\n",
              "      <td>0.1673</td>\n",
              "      <td>...</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.3621</td>\n",
              "      <td>0.8182</td>\n",
              "      <td>0.2996</td>\n",
              "      <td>0.5370</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.1525</td>\n",
              "      <td>0.4839</td>\n",
              "      <td>0.7595</td>\n",
              "      <td>0.5082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2679</td>\n",
              "      <td>0.3912</td>\n",
              "      <td>0.2992</td>\n",
              "      <td>0.3636</td>\n",
              "      <td>0.4138</td>\n",
              "      <td>0.1429</td>\n",
              "      <td>0.1351</td>\n",
              "      <td>0.3621</td>\n",
              "      <td>0.1993</td>\n",
              "      <td>...</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.5172</td>\n",
              "      <td>0.5758</td>\n",
              "      <td>0.1167</td>\n",
              "      <td>0.6667</td>\n",
              "      <td>0.5273</td>\n",
              "      <td>0.1186</td>\n",
              "      <td>0.1290</td>\n",
              "      <td>0.2405</td>\n",
              "      <td>0.4262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4643</td>\n",
              "      <td>0.2971</td>\n",
              "      <td>0.6081</td>\n",
              "      <td>0.5682</td>\n",
              "      <td>0.6983</td>\n",
              "      <td>0.7460</td>\n",
              "      <td>0.6757</td>\n",
              "      <td>0.9655</td>\n",
              "      <td>0.4377</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.8448</td>\n",
              "      <td>0.5455</td>\n",
              "      <td>0.1790</td>\n",
              "      <td>0.5185</td>\n",
              "      <td>0.5455</td>\n",
              "      <td>0.1017</td>\n",
              "      <td>0.0968</td>\n",
              "      <td>0.6709</td>\n",
              "      <td>0.4426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7143</td>\n",
              "      <td>0.2029</td>\n",
              "      <td>0.6023</td>\n",
              "      <td>0.5682</td>\n",
              "      <td>0.6897</td>\n",
              "      <td>0.7143</td>\n",
              "      <td>0.5946</td>\n",
              "      <td>0.3103</td>\n",
              "      <td>0.4840</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.8448</td>\n",
              "      <td>0.4545</td>\n",
              "      <td>0.6304</td>\n",
              "      <td>0.1296</td>\n",
              "      <td>0.4091</td>\n",
              "      <td>0.4576</td>\n",
              "      <td>0.4839</td>\n",
              "      <td>0.7975</td>\n",
              "      <td>0.6557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6786</td>\n",
              "      <td>0.1021</td>\n",
              "      <td>0.4093</td>\n",
              "      <td>0.5227</td>\n",
              "      <td>0.4397</td>\n",
              "      <td>0.2698</td>\n",
              "      <td>0.6486</td>\n",
              "      <td>0.3621</td>\n",
              "      <td>0.3879</td>\n",
              "      <td>...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8276</td>\n",
              "      <td>0.5227</td>\n",
              "      <td>0.1751</td>\n",
              "      <td>0.2778</td>\n",
              "      <td>0.6364</td>\n",
              "      <td>0.1186</td>\n",
              "      <td>0.5484</td>\n",
              "      <td>0.3291</td>\n",
              "      <td>0.7049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.3929</td>\n",
              "      <td>0.6897</td>\n",
              "      <td>0.2838</td>\n",
              "      <td>0.4545</td>\n",
              "      <td>0.3017</td>\n",
              "      <td>0.2540</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4483</td>\n",
              "      <td>0.2135</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4655</td>\n",
              "      <td>0.6818</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.5741</td>\n",
              "      <td>0.6636</td>\n",
              "      <td>0.0339</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2152</td>\n",
              "      <td>0.3770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7321</td>\n",
              "      <td>0.2361</td>\n",
              "      <td>0.4054</td>\n",
              "      <td>0.3182</td>\n",
              "      <td>0.6466</td>\n",
              "      <td>0.4921</td>\n",
              "      <td>0.2162</td>\n",
              "      <td>0.3621</td>\n",
              "      <td>0.2313</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.5345</td>\n",
              "      <td>0.8561</td>\n",
              "      <td>0.1907</td>\n",
              "      <td>0.4444</td>\n",
              "      <td>0.9455</td>\n",
              "      <td>0.1017</td>\n",
              "      <td>0.2258</td>\n",
              "      <td>0.3544</td>\n",
              "      <td>0.4754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1964</td>\n",
              "      <td>0.6844</td>\n",
              "      <td>0.3359</td>\n",
              "      <td>0.5455</td>\n",
              "      <td>0.3017</td>\n",
              "      <td>0.3492</td>\n",
              "      <td>0.4595</td>\n",
              "      <td>0.3793</td>\n",
              "      <td>0.2883</td>\n",
              "      <td>...</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.3966</td>\n",
              "      <td>0.5909</td>\n",
              "      <td>0.1051</td>\n",
              "      <td>0.4444</td>\n",
              "      <td>0.6636</td>\n",
              "      <td>0.0847</td>\n",
              "      <td>0.1613</td>\n",
              "      <td>0.1899</td>\n",
              "      <td>0.3607</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57bce0a5-9848-44ed-b2e5-3500c2dae5d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57bce0a5-9848-44ed-b2e5-3500c2dae5d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57bce0a5-9848-44ed-b2e5-3500c2dae5d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperParameter(df3)"
      ],
      "metadata": {
        "id": "c8lX_3h8lxg3",
        "outputId": "ed421b38-a092-4391-f06d-70a01b926c66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-1834599e46ea>:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  X = data.drop('telomere length (kb)',1)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "13500 fits failed out of a total of 20250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6750 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 384, in _fit\n",
            "    self._validate_hyperparameters()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 493, in _validate_hyperparameters\n",
            "    raise ValueError(\n",
            "ValueError: The activation 'LeakyReLU' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6750 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 384, in _fit\n",
            "    self._validate_hyperparameters()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 493, in _validate_hyperparameters\n",
            "    raise ValueError(\n",
            "ValueError: The activation 'identify' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.52090387 0.52041515 0.33303072 ...        nan        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:984: RuntimeWarning: invalid value encountered in cast\n",
            "  results[\"rank_%s\" % key_name] = np.asarray(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'batch_size': 4,\n",
              " 'hidden_layer_sizes': (150, 100, 50),\n",
              " 'learning_rate_init': 0.001,\n",
              " 'max_iter': 200,\n",
              " 'random_state': 216,\n",
              " 'solver': 'sgd'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df3['telomere length (kb)']\n",
        "X = df3.drop('telomere length (kb)',1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhOqg4Me4Wwe",
        "outputId": "2a135ae5-69ed-4624-faa9-6cacb3c8a299"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-2db422769c5c>:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  X = df3.drop('telomere length (kb)',1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=216)"
      ],
      "metadata": {
        "id": "MQBRBTSV4YG6"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLPRegressor(hidden_layer_sizes=(150, 100, 50),activation = 'relu',solver = 'sgd',\n",
        "                     learning_rate_init = 0.001, max_iter = 200, batch_size = 4, random_state=216)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0scFr3a4YV6",
        "outputId": "9363aa4f-3e6d-4c89-cc15-fea66ef89396"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(batch_size=4, hidden_layer_sizes=(150, 100, 50), random_state=216,\n",
              "             solver='sgd')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "RaCQGv4_HiPv"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "print('R2 Value Train:',metrics.r2_score(y_train, model.predict(X_train)))\n",
        "print('MSE Train:',metrics.mean_squared_error(y_train, model.predict(X_train)))\n",
        "print('MAE Train:',metrics.mean_absolute_error(y_train, model.predict(X_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YME-Y4P-4aM3",
        "outputId": "ee26fd9d-c2ce-4bf3-92e3-2cb982969456"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Value Train: 0.743969883827551\n",
            "MSE Train: 0.008864313677002326\n",
            "MAE Train: 0.07991909719241036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('MAPE :',mean_absolute_percentage_error(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMvxlnHIGx4w",
        "outputId": "090961f9-1373-4f7b-ceba-c6ae6d1c5776"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAPE : 0.3446736918770495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "print('R2 Value Test:',metrics.r2_score(y_test, y_pred))\n",
        "print('MSE Test:',metrics.mean_squared_error(y_test, y_pred))\n",
        "print('MAE Test:',metrics.mean_absolute_error(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVM4XY8xHbhs",
        "outputId": "e5b92659-d2d2-427b-ab0a-9ce2e732fc00"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Value Test: 0.6896391761562977\n",
            "MSE Test: 0.019505660616035946\n",
            "MAE Test: 0.11608294974685071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(y_pred, hist = False, color = 'r', label = 'Predicted Values')\n",
        "sns.distplot(y_test, hist = False, color = 'b', label = 'Actual Values')\n",
        "plt.title('Actual vs Predicted Values', fontsize = 16)\n",
        "plt.xlabel('Values', fontsize = 12)\n",
        "plt.ylabel('Frequency', fontsize = 12)\n",
        "plt.legend(loc = 'upper left', fontsize = 13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "HADH3Q8gdxEv",
        "outputId": "79a53ab8-1024-499c-dc93-3844776cf7e2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb30629fa30>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}